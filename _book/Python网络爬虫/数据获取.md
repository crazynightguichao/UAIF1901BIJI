# 第3节：数据获取
## 数据采集
### 1.urllib包  （包里有丰富的API）
#### 概述
uillib是一个收集了多个使用URL的模块的软件包
#### 组件
* request：打开和阅读url地址的包

    urllib.request
* error：包含 urllib.request 抛出的异常

    urllib.error
* parse：用于处理 URL
urllib.parse
    ```
	编码转换
		parse.urlencode({}）
		quote("太原"）:把汉字转换为编码
		urlparse(url):解析url各个部分
    ```
* robotparser：用于解析 robots.txt 文件

  urllib.robotparser
#### 响应类型为json
* json.loads(str)      将 str 转换为 dict
* json.dumps(dict)     将 dict 转换为 str
### 2.[requests包](http://docs.python-requests.org/zh_CN/latest/)
通过urllib底层实现（在urllib的基础上进行更好的封装）
#### GET请求
get(URL,params,headers,timeout)

	res = requests.get('www.baidu.com')   响应一个地址

	res.text  查看响应内容
    res.content  字节流
    res.url  完整的地址
    res.encoding  响应字符编码
    res.status_code  响应码
#### POST请求
post(URL,data,header={})

	data={}

	res.text
    res.json()  显示json
#### 代理
proxies = {"http":"http：//12.34.56.79:9527"}
response = response.get("http://www.baidu.com",proxies = proxies)

	proxie = {
        'http':'http://%s'%ip,
        'https': 'https://%s'%ip,
    }

	requests.get('http://wwww.baidu.com',proxies=proxie,timeout=10)     # 请求百度，测试ip地址是否可用
本地配置代理

	export HTTP_PROXY="http://12.34.56.79.9527"
	export HTTPS_PROXY="https://12.34.56.79.9527"
#### cookie和session（保存在浏览器的数据）
* 包中利用cookie以及session来实现登录
* 日报实例:日报系统中找到学生id
可以在布局里找，也可以在updatecontent里找，就是提交两次可以出现。
* 获取cookie
#### 处理HTTPS请求SSL证书验证
response = requests.get("https://www.baidu.com/",verify=True)

跳过验证 verify=False （默认）
### 3.fake-useragent  工具
* 安装  pip install fake-useragent import User Agent

* 使用
    ```
	ua=User Agent（）
	ua.ie
	ua.firefox
	ua.chrome
	ua.random
    ```
### 4.[Selenium（浏览器测试）](https://selenium-python-zh.readthedocs.io/en/latest/)
一、概述

Selenium是一个web的自动化测试工具，最初是为网站自动化测试而开发的，类型像我们玩游戏时用的按键精灵，可以按指定的命令自动操作，不同的是Selenium可以直接运行在浏览器上，它支持所有主流的浏览器（包括PhantomJS这些无界面的浏览器）

[中文文档](https://selenium-python-zh.readthedocs.io/en/latest/)

 安装:pip install selenium

 [安装 ChromeDriver Mirror](http://npm.taobao.org/mirrors/chromedriver/)

二、 常用组件

webdriver

##### 操作步骤

1. 导入 from selenium import webdriver
2. driver.get("http://118.190.150.35:9000/login")
打开网址，打开需要时间，建议time.sleep()
3. 操作数据
4. drive.quit()  关闭浏览器

##### 详细操作
① [获取页面元素](https://selenium-python-zh.readthedocs.io/en/latest/locating-elements.html#locating-elements)
* driver.find_element_by_id('loginForm') #通过ID获取元素

* driver.find_element_by_name('continue') #通过name属性获取元素
* driver.find_element_by_xpath("//form[@id='loginForm']/input[4]") #通过XPath查找元素
* driver.find_element_by_link_text('Continue')	#通过链接文本获取超链接
* driver.find_element_by_partial_link_text('Conti')
* driver.find_element_by_tag_name('h1') #通过标签名查找元素
* driver.find_element_by_class_name('content') #通过Class name 定位元素
* driver.find_element_by_css_selector('p.content') #通过CSS选择器查找元素

② 事件
* 步骤
1. from selenium.webdriver import ActionChains
 导入 ActionChains 类
2. loginbtn = driver.find_element_by_partial_link_text("登") 
 获取元素
3. action = ActionChains(driver)
 创建对象
4. action.click(loginbtn)
 填写事件
5. action.click(loginbtn).perform()  
 执行
* 事件
    ```
    click()  单击
    double_click()  双击
    context_click(ac)  右击
    click_and_hold()  按下
    drag_and_drop(e1,e2)  将元素e1移动到e2
    drag_and_drop_by_offset(e1,x,y)  将元素移动位置
    release(e)  释放鼠标按钮
    pause(num)  停几秒
    send_keys(con)  将con发送到当前聚焦元素
    send_keys_to_element(ele,con)  将con发送到元素
    ```
 ③ 下拉框处理

步骤
```
1. from selenium.webdriver.support.ui import Select
    导入select类
2. select = Select（ele）
    创建选择对象
3.  select_by_index(1)
    select_by_value("0")
    select_by_visible_rext("选择的内容")
    deselect_all()  取消选择
```
④ 弹窗处理
```
alert = driver.switch to alert()  获取弹框内容
```
⑤ 页面切换
```
driver.switch_to_alert()  获取弹窗内容
for handle in driver.window_handles:
driver.switch_to_window(handle)
```
⑥ 页面前进和后退
```
driver.forward()  #前进
driver.back()  #后退
```
⑦ Cookies
```
driver.get_cookie()  # 获取cookies
driver.delete_cookie("key")  # 删除对应cookie
driver.delete_all_coolies()  # 删除全部cookie
```
⑧ [页面等待](https://selenium-python-zh.readthedocs.io/en/latest/waits.html#id2)
* 显式等待
* 隐式等待

⑨ 补充(瀑布流布局)
```
dirver.execute_script()
执行JavaScript 脚本

driver.quit()
关闭浏览器

dirver.save_screenshot('abc.png')
页面快照

dirver.page_source
页面源码
```
```
案例:瀑布流布局
### 瀑布流布局
url = "https://unsplash.com/t/wallpapers"
driver.get(url)
driver.execute_script("window.scrollTo(0,2000)")        # 执行JavaScript脚本

time.sleep(5)
with open("img.html",'w',encoding='utf-8') as f:
    f.write(driver.page_source)     # 页面源码

driver.save_screenshot("img.png")       # 页面快照
driver.close()      # 关闭浏览器
```
三、 处理：通过js写的，页面加载；滚动
### 5.验证码处理

## 页面数据解析
### lxml
#### Xpath常用规则
* 安装
```
pip install lxml
from lxml import etree
```
* // 从当前节点选取后代节点
```
# root = html.xpath("//div")      # 从当前节点找，任意位置，后加上标签名div
```
* NodeName  选取此节点的所有子节点
* /  从当前节点选取子节点
```
	# root = html.xpath("/div")      # div标签名，从根开始找(找不见)
```
* .  当前节点
```
	# links = html.xpath("//div/ul/li/a/./../div")
```
* .. 当前节点的父节点
```
	link = html.xpath("//div/ul/li/a/../div")
```
* @  选择所有属性
```
	/@herf  获取herf属性
	/@*  获取元素全部属性
```
* [tag] 选取所有具有指定元素的直接子节点
```
	# links = html.xpath("//div/ul/li[a]")      # [tag]里是条件，获取拥有特点元素的节点 
```
* [tag = 'text']  
```选取所有具有元素并且文本内容是text的节点
	# links = html.xpath("//div/ul/li[a='优逸客']")      # [tag = text]里是条件，获取拥有特点元素值的节点
```
* 节点轴
```
## XPath 轴
# links = html.xpath("//div/ul/li/child::div")      # li 下面所有的 div
# print(links)

# links = html.xpath("//div/ul/li/attribute::class")      # li 下面所有的 class类名
# print(links)

# links = html.xpath("//div/ul/li/child::text()")      # li 下面所有的子类的内容
# print(links)

# links = html.xpath("//div/ul/li[last()]/child::*")      # li 下面所有的子元素
# print(links)

# links = html.xpath("//div/ul/li/child::node()")      # li 下面所有的子元素
# print(links)

# links = html.xpath("//div/ul/li/descendant::*")      # li 下面所有的后代元素
# print(links)

# links = html.xpath("//div/ul/parent::*")      # ul 父元素
# print(links)

# links = html.xpath("//div/ul/ancestor::*")      # ul 所有的祖先元素
# print(links)

# links = html.xpath("//div/ul/li[last()]/a/preceding::*")      # 当前元素之前的所有节点
# print(links)
```
* 常用函数
contains（）
```
# links = html.xpath("//div/ul/li/a[@class='link1 link3']")      #  直接用类名获取元素，两个类名都得写
# print(links)

# links = html.xpath("//div/ul/li/a[contains(@class,'link1')]")      #  用contains获取元素，只要写一个类名就可以
# print(links)
```
last（）
```
links = html.xpath("//div/ul/li[position()<last()]/a/text()")      # [position()]里是条件，获取拥有特点元素值的节点
print(links)
```
#### 组件
etree（文档树）
```
	HTML初始化生成一个XPath解析
	tostring（html，encoding=''）
	xpath() 通过获取路径来获取资源
```
```
为什么请求一个地址可以打开？
浏览器是个什么样的存在可以把网页打开？网页又是一个什么样的存在（html）？
网页在别的电脑上，怎样通过浏览器把别人电脑上的网页拿回来？
获取数据的软件：通过你输入的请求，把地址转换成哪个电脑上的哪个软件的哪个应用。
找见对应的服务器对应的软件的内容，把它的内容发送给你，通过网络传输回来，传回到本地。本地就是把传输回来的数据呈现出来。传输的过程全部是二进制的方式，解析完之后依旧是一个字符串，不是一个对象节点。
是谁帮你把它做成了对象节点？就是js引擎，浏览器内核帮你解析的。从字符串到具体呈现出一个对象，是浏览器帮你做的。
我们通过程序请求，没有浏览器帮我们处理，通过python请求的，python没有浏览器内核，没有办法帮你解析字符串。但是它能拿到文本，不会给你画出来。把字符串变成一个文档树。

```
### re  正则
#### 概述
用来描述或者匹配一系列符合某种规则得字符串的表达式

（输入用户名密码，长度不够，特殊符号，怎样知道输入的格式对不对）
#### 正则表达式
* 元字符
```
对一类字符进行描述

# \w 字符
# res = re.findall(r"\w","123abcdef_$^<>")        # \w只匹配一个字符,命名的时候可以命名什么
# print(res)
# \W 非字符
# res = re.findall(r"\W","123abcdef_$^<>")
# print(res)
# \d 数字
# res = re.findall(r"\d","123abcdef_$^<>")
# print(res)
# \D 非数字
# res = re.findall(r"\D","123abcdef_$^<>")
# print(res)
# \b 单词边界(单词边界就是空)
# res = re.findall(r"\bi","this is div")
# print(res)
# \B 非单词边界
# res = re.findall(r"\Bi","this is div")
# # print(res)
# \s 空
# res = re.findall(r"\s","this is div")
# print(res)
# \S 非空
# res = re.findall(r"\S","this is div")
# print(res)
# . 除了\n 以外的所有字符
# res = re.findall(r".","this is div")
# print(res)

```
* 原子表
```
原子表   也是匹配一位字符,可以连一起找
  []    类似一个列表

# [abc]
# [a-z]
# [A-Z]
# [a-zA-Z1-9]
# [^...]  取反
# res = re.findall(r"[hs]","this is div")     # 匹配h和s
# res = re.findall(r"[a-z]","this is DIV")        # 匹配小写字母
# res = re.findall(r"[^A-Z]","this is DIV")        # 取反
# print(res)
```
* 数量
```
*   0个或多个字符
+   1个或多个
？  0个或1个
{n}    n个
{n,}  n个或多个
{n,m}  n个到m个
res = re.findall(r"\w*","this is div")
res = re.findall(r"\w+","this is div")
res = re.findall(r"\w?","this is div")
res = re.findall(r"an?","this is a an div")     # 后边的n可有可无
res = re.findall(r"</?div>?","<div>this is div</div>")      # / 可有可无
res = re.findall(r"\w{2}","abcdefg")
res = re.findall(r"\w{2,3}","this is div")      # 贪婪特点：尽可能多
res = re.findall(r"\w{2,}","this is div")       # 贪婪： 选择全部
print(res)
```
* 其他
```
^  以什么开始
$   以什么结束
a|b  a或b
()   表示一个组
```
```
  () 组
  (?P=name)  命名组、定义组
  正则表达式中调用   (?P=name)    \1  \2..
  正则对象中  res.group(n)   res.groupdict()

res4 = re.search(r'<?P<tag>\w+>(?P<con>.*)</(?P=tag)>','<div>this is div</div>')
res4 = re.search(r'<?P<tag>\w+>(?P<con>.*)</(\1)>','<div>this is div</div>')
print(res4)
```
#### re 模块
* re常用函数

1.re.match(pattern,string,flags=0)
```
pattern  正则表达式
steing  要匹配的字符串
flag  模式

尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话

成功返回正则对象
    group(num=0)
    groups()
```
2.re.search(pattern,string,flags=0)
```
pattern  正则表达式
steing  要匹配的字符串
flag  模式
re.search() 扫描整个字符串并返回第一个成功的匹配
成功返回正则对象
    group(num=0)
    groups()
```
3.re.sub(pattern,repl,string,count=0,flags=0)
```
pattern  正则中的模式字符串
repl  替换的字符串也可为一个函数
string  要被查找替换的原始字符串
count  模式匹配后替换的最大次数，默认0，表示替换所有的匹配
```
```
## sub  替换函数
# res = re.sub("山西","陕西","山西优逸客","陕西",1)
# def fn(a):
#     res = str(int(a.group())*2)
#     return res
#
# res = re.sub("\d+",fn,"山西优逸客 就业人数1000 高薪就业900")
# print(res)
```
4.re.compile(pattern[,flags])
```
pattern  一个字符串形式的正则表达式
flags  可选，表示匹配模式
```
5.re.findall(string[,pos[,endpos]])
```
在字符串中找到正则表达式所匹配的所有子串，并且返回一个列表，如果没有找到匹配的，则返回空列表。

string  待匹配的字符串
pos  可选参数，指定字符串的起始位置，默认为0
endpos  可选参数，指定字符串的结束位置，默认为字符串的长度
```
6.re.finditer()
```
返回一个迭代器。可以循环的、一次性输出
```
7.re.split(pattern,string[,maxsplit=0,flags=0])
```
pattern  匹配的正则表达式
string  要匹配的字符串
maxsplit  分割次数
flags  标志位

## split 拆分函数
# rege = re.compile('[;,.]')     # 正则表达式,变成原子表
# res5 = rege.split('a;b,c.d')
# res5 = re.split('[;,.]','a;b,c.d')
# print(res5)
```
* 匹配模式
```
re.I  忽略大小写
re.L  表示特殊字符集 \w , \W,  \b ,\B, \s ,\S 依赖于当前环境
re.M  多行模式
re.S  使特殊字符匹配任何字符，包括换行，如果没有此标志，将匹配任何内容除换行符
re.X  此标志允许编写正则表达式，看起来更好。在模式中的空白将被忽略，除非当在字符类或者前面非转义反斜杠和当一条线包含一个# ，既不在字符类中或由非转义反斜杠，从最左侧的所有字符之前，这种# 通过行末尾将被忽略。
```
```
## 匹配模式
# rege = re.compile('[a-z]',re.I)        # re.I忽略大小写
# res = rege.findall("absdhoashODISAHNO")
# print(res)

# rege = re.compile("""[a-z] # 字母""",re.X)
# res = rege.findall("""
# absdhoashODISAHNO
# hfadshfi
# """)
# print(res)
```
### bs4
### PyQuery